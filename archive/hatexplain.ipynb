{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acb1e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tum-nlp/bert-hateXplain\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"tum-nlp/bert-hateXplain\")\n",
    "hate_classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_csv(\"../mdatasci/compsci-760/project/supervision_test10_threads.csv\")\n",
    "df = df.rename(columns={\"is_hate\": \"is_hate_legacy\", \"hate_label\": \"hate_label_legacy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token_length(text: str) -> int:\n",
    "    try:\n",
    "        encoded_input_fixed = tokenizer(\n",
    "            text, max_length=512, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        return encoded_input_fixed[\"input_ids\"].shape[1]\n",
    "    except Exception as e:\n",
    "        print(text)\n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "\n",
    "df = df[df[\"body\"].notnull()].copy()\n",
    "df[\"token_len\"] = df[\"body\"].map(get_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 918 posts.\n",
      "Shape before: (918, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying posts: 100%|██████████| 918/918 [00:04<00:00, 227.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after: (918, 12)\n",
      "hate_label\n",
      "non-toxic    811\n",
      "toxic        107\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text):\n",
    "    clean_text = str(text).replace(\"\\n\", \" \")\n",
    "    result = hate_classifier(clean_text)\n",
    "    return result[0][\"label\"], result[0][\"score\"]\n",
    "\n",
    "\n",
    "valid_df = df[\n",
    "    (df[\"body\"] != \"[removed]\") & (df[\"body\"] != \"[deleted]\") & (df[\"token_len\"] < 512)\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(valid_df)} posts.\")\n",
    "\n",
    "tqdm.pandas(desc=\"Classifying posts\")\n",
    "\n",
    "print(f\"Shape before: {valid_df.shape}\")\n",
    "\n",
    "classification_results = valid_df[\"body\"].progress_apply(classify_text)\n",
    "valid_df[\"hate_label\"] = [result[0] for result in classification_results]\n",
    "valid_df[\"hate_score\"] = [result[1] for result in classification_results]\n",
    "\n",
    "print(f\"Shape after: {valid_df.shape}\")\n",
    "print(valid_df[\"hate_label\"].value_counts())\n",
    "valid_df = valid_df.sort_values(\"hate_score\")\n",
    "valid_df.to_csv(\"supervision_test10_threads_hatexplain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20645f",
   "metadata": {},
   "source": [
    "## Scratchpad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c41d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = (\n",
    "    pl.read_csv(\n",
    "        \"/Users/sujay/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Course Documents/COMPSCI 760/Project/COMPSCI 760 - Group Project/Sample Data/addNew/retrain_validation10.csv\"\n",
    "    )\n",
    "    .drop_nans()\n",
    "    .drop_nulls()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 3)\n",
      "┌───────────────────┬──────────────┬───────────────┐\n",
      "│ subreddit         ┆ avg_toxicity ┆ comment_count │\n",
      "│ ---               ┆ ---          ┆ ---           │\n",
      "│ str               ┆ f64          ┆ u32           │\n",
      "╞═══════════════════╪══════════════╪═══════════════╡\n",
      "│ The_Donald        ┆ 0.33245      ┆ 21866         │\n",
      "│ news              ┆ 0.315804     ┆ 11310         │\n",
      "│ todayilearned     ┆ 0.313934     ┆ 10129         │\n",
      "│ worldnews         ┆ 0.304131     ┆ 11230         │\n",
      "│ politics          ┆ 0.299645     ┆ 39005         │\n",
      "│ pics              ┆ 0.295496     ┆ 7349          │\n",
      "│ gifs              ┆ 0.295433     ┆ 7733          │\n",
      "│ mildlyinteresting ┆ 0.294152     ┆ 3453          │\n",
      "│ videos            ┆ 0.291407     ┆ 7057          │\n",
      "│ AskReddit         ┆ 0.28538      ┆ 76132         │\n",
      "└───────────────────┴──────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    df.group_by(\"subreddit\")\n",
    "    .agg(\n",
    "        pl.col(\"toxicity_probability_self\").mean().alias(\"avg_toxicity\"),\n",
    "        pl.len().alias(\"comment_count\"),\n",
    "    )\n",
    "    .top_k(by=\"avg_toxicity\", k=1000)\n",
    "    .top_k(by=\"comment_count\", k=10)\n",
    "    .sort(\"avg_toxicity\", descending=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
